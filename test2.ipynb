{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pickle\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uqq fastai torchvision pickle\n",
    "\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor(),\n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at `train_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataloaders `dl`, `valid_dl` and `dls`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "valid_dl = DataLoader(test_data, batch_size=100, shuffle=True)\n",
    "dls = DataLoaders(dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `Net` from `learning_functions.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learning_functions import Net\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Use GPU if available\n",
    "neural_net = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `learn` function from `neural_net`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from learning_functions import batch_accuracy\n",
    "\n",
    "learn = Learner(dls, neural_net, opt_func=SGD, loss_func=nn.CrossEntropyLoss(), metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(neural_net.parameters(), lr=0.2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    neural_net.train()\n",
    "    global optimizer\n",
    "    for batch_idx, (data, target) in enumerate(dl):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = neural_net(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx*len(data)}/{len(dl.dataset)} ({100. * batch_idx / len(dl):.0f}%)]\\t{loss.item():.6f}\")\n",
    "\n",
    "def test():\n",
    "    neural_net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in valid_dl:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = neural_net(data)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= len(valid_dl.dataset)\n",
    "    print(f'\\nTest Loss: Average Loss: {test_loss:.4f}, Accuracy: {correct}/{len(valid_dl.dataset)} {100. * correct / len(valid_dl.dataset):.0f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/preston/Projects/fastai_course/MNIST_Digit_identifier/learning_functions.py:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\t2.302407\n",
      "Train Epoch: 1 [2000/60000 (3%)]\t2.302410\n",
      "Train Epoch: 1 [4000/60000 (7%)]\t2.301476\n",
      "Train Epoch: 1 [6000/60000 (10%)]\t2.300585\n",
      "Train Epoch: 1 [8000/60000 (13%)]\t2.299006\n",
      "Train Epoch: 1 [10000/60000 (17%)]\t2.297978\n",
      "Train Epoch: 1 [12000/60000 (20%)]\t2.295551\n",
      "Train Epoch: 1 [14000/60000 (23%)]\t2.290289\n",
      "Train Epoch: 1 [16000/60000 (27%)]\t2.291070\n",
      "Train Epoch: 1 [18000/60000 (30%)]\t2.242637\n",
      "Train Epoch: 1 [20000/60000 (33%)]\t2.222497\n",
      "Train Epoch: 1 [22000/60000 (37%)]\t2.127462\n",
      "Train Epoch: 1 [24000/60000 (40%)]\t2.014867\n",
      "Train Epoch: 1 [26000/60000 (43%)]\t1.943990\n",
      "Train Epoch: 1 [28000/60000 (47%)]\t1.970862\n",
      "Train Epoch: 1 [30000/60000 (50%)]\t1.835616\n",
      "Train Epoch: 1 [32000/60000 (53%)]\t1.796894\n",
      "Train Epoch: 1 [34000/60000 (57%)]\t1.809688\n",
      "Train Epoch: 1 [36000/60000 (60%)]\t1.802201\n",
      "Train Epoch: 1 [38000/60000 (63%)]\t1.845780\n",
      "Train Epoch: 1 [40000/60000 (67%)]\t1.720463\n",
      "Train Epoch: 1 [42000/60000 (70%)]\t1.787964\n",
      "Train Epoch: 1 [44000/60000 (73%)]\t1.733008\n",
      "Train Epoch: 1 [46000/60000 (77%)]\t1.737468\n",
      "Train Epoch: 1 [48000/60000 (80%)]\t1.818817\n",
      "Train Epoch: 1 [50000/60000 (83%)]\t1.828468\n",
      "Train Epoch: 1 [52000/60000 (87%)]\t1.639774\n",
      "Train Epoch: 1 [54000/60000 (90%)]\t1.695041\n",
      "Train Epoch: 1 [56000/60000 (93%)]\t1.731217\n",
      "Train Epoch: 1 [58000/60000 (97%)]\t1.840982\n",
      "\n",
      "Test Loss: Average Loss: 0.0163, Accuracy: 8355/10000 84%\n",
      "Train Epoch: 2 [0/60000 (0%)]\t1.683293\n",
      "Train Epoch: 2 [2000/60000 (3%)]\t1.683400\n",
      "Train Epoch: 2 [4000/60000 (7%)]\t1.683695\n",
      "Train Epoch: 2 [6000/60000 (10%)]\t1.719783\n",
      "Train Epoch: 2 [8000/60000 (13%)]\t1.710228\n",
      "Train Epoch: 2 [10000/60000 (17%)]\t1.680496\n",
      "Train Epoch: 2 [12000/60000 (20%)]\t1.690790\n",
      "Train Epoch: 2 [14000/60000 (23%)]\t1.708682\n",
      "Train Epoch: 2 [16000/60000 (27%)]\t1.673393\n",
      "Train Epoch: 2 [18000/60000 (30%)]\t1.653967\n",
      "Train Epoch: 2 [20000/60000 (33%)]\t1.643647\n",
      "Train Epoch: 2 [22000/60000 (37%)]\t1.601620\n",
      "Train Epoch: 2 [24000/60000 (40%)]\t1.661895\n",
      "Train Epoch: 2 [26000/60000 (43%)]\t1.631917\n",
      "Train Epoch: 2 [28000/60000 (47%)]\t1.676624\n",
      "Train Epoch: 2 [30000/60000 (50%)]\t1.584460\n",
      "Train Epoch: 2 [32000/60000 (53%)]\t1.614076\n",
      "Train Epoch: 2 [34000/60000 (57%)]\t1.678260\n",
      "Train Epoch: 2 [36000/60000 (60%)]\t1.603151\n",
      "Train Epoch: 2 [38000/60000 (63%)]\t1.617052\n",
      "Train Epoch: 2 [40000/60000 (67%)]\t1.650736\n",
      "Train Epoch: 2 [42000/60000 (70%)]\t1.611332\n",
      "Train Epoch: 2 [44000/60000 (73%)]\t1.631997\n",
      "Train Epoch: 2 [46000/60000 (77%)]\t1.606014\n",
      "Train Epoch: 2 [48000/60000 (80%)]\t1.645590\n",
      "Train Epoch: 2 [50000/60000 (83%)]\t1.618459\n",
      "Train Epoch: 2 [52000/60000 (87%)]\t1.650843\n",
      "Train Epoch: 2 [54000/60000 (90%)]\t1.566066\n",
      "Train Epoch: 2 [56000/60000 (93%)]\t1.610957\n",
      "Train Epoch: 2 [58000/60000 (97%)]\t1.570655\n",
      "\n",
      "Test Loss: Average Loss: 0.0153, Accuracy: 9319/10000 93%\n",
      "Train Epoch: 3 [0/60000 (0%)]\t1.675718\n",
      "Train Epoch: 3 [2000/60000 (3%)]\t1.643471\n",
      "Train Epoch: 3 [4000/60000 (7%)]\t1.679093\n",
      "Train Epoch: 3 [6000/60000 (10%)]\t1.613596\n",
      "Train Epoch: 3 [8000/60000 (13%)]\t1.560670\n",
      "Train Epoch: 3 [10000/60000 (17%)]\t1.541491\n",
      "Train Epoch: 3 [12000/60000 (20%)]\t1.604757\n",
      "Train Epoch: 3 [14000/60000 (23%)]\t1.613638\n",
      "Train Epoch: 3 [16000/60000 (27%)]\t1.518227\n",
      "Train Epoch: 3 [18000/60000 (30%)]\t1.566728\n",
      "Train Epoch: 3 [20000/60000 (33%)]\t1.554493\n",
      "Train Epoch: 3 [22000/60000 (37%)]\t1.575144\n",
      "Train Epoch: 3 [24000/60000 (40%)]\t1.592171\n",
      "Train Epoch: 3 [26000/60000 (43%)]\t1.613449\n",
      "Train Epoch: 3 [28000/60000 (47%)]\t1.680622\n",
      "Train Epoch: 3 [30000/60000 (50%)]\t1.605267\n",
      "Train Epoch: 3 [32000/60000 (53%)]\t1.563811\n",
      "Train Epoch: 3 [34000/60000 (57%)]\t1.570157\n",
      "Train Epoch: 3 [36000/60000 (60%)]\t1.580707\n",
      "Train Epoch: 3 [38000/60000 (63%)]\t1.575047\n",
      "Train Epoch: 3 [40000/60000 (67%)]\t1.593595\n",
      "Train Epoch: 3 [42000/60000 (70%)]\t1.626760\n",
      "Train Epoch: 3 [44000/60000 (73%)]\t1.597599\n",
      "Train Epoch: 3 [46000/60000 (77%)]\t1.570261\n",
      "Train Epoch: 3 [48000/60000 (80%)]\t1.594185\n",
      "Train Epoch: 3 [50000/60000 (83%)]\t1.541182\n",
      "Train Epoch: 3 [52000/60000 (87%)]\t1.585066\n",
      "Train Epoch: 3 [54000/60000 (90%)]\t1.519551\n",
      "Train Epoch: 3 [56000/60000 (93%)]\t1.556841\n",
      "Train Epoch: 3 [58000/60000 (97%)]\t1.589567\n",
      "\n",
      "Test Loss: Average Loss: 0.0152, Accuracy: 9442/10000 94%\n",
      "Train Epoch: 4 [0/60000 (0%)]\t1.609256\n",
      "Train Epoch: 4 [2000/60000 (3%)]\t1.585327\n",
      "Train Epoch: 4 [4000/60000 (7%)]\t1.596654\n",
      "Train Epoch: 4 [6000/60000 (10%)]\t1.563310\n",
      "Train Epoch: 4 [8000/60000 (13%)]\t1.582247\n",
      "Train Epoch: 4 [10000/60000 (17%)]\t1.553099\n",
      "Train Epoch: 4 [12000/60000 (20%)]\t1.558994\n",
      "Train Epoch: 4 [14000/60000 (23%)]\t1.577372\n",
      "Train Epoch: 4 [16000/60000 (27%)]\t1.601973\n",
      "Train Epoch: 4 [18000/60000 (30%)]\t1.576435\n",
      "Train Epoch: 4 [20000/60000 (33%)]\t1.560277\n",
      "Train Epoch: 4 [22000/60000 (37%)]\t1.558144\n",
      "Train Epoch: 4 [24000/60000 (40%)]\t1.530397\n",
      "Train Epoch: 4 [26000/60000 (43%)]\t1.574886\n",
      "Train Epoch: 4 [28000/60000 (47%)]\t1.530655\n",
      "Train Epoch: 4 [30000/60000 (50%)]\t1.559395\n",
      "Train Epoch: 4 [32000/60000 (53%)]\t1.600444\n",
      "Train Epoch: 4 [34000/60000 (57%)]\t1.555398\n",
      "Train Epoch: 4 [36000/60000 (60%)]\t1.535166\n",
      "Train Epoch: 4 [38000/60000 (63%)]\t1.569857\n",
      "Train Epoch: 4 [40000/60000 (67%)]\t1.589106\n",
      "Train Epoch: 4 [42000/60000 (70%)]\t1.651255\n",
      "Train Epoch: 4 [44000/60000 (73%)]\t1.494643\n",
      "Train Epoch: 4 [46000/60000 (77%)]\t1.571713\n",
      "Train Epoch: 4 [48000/60000 (80%)]\t1.558314\n",
      "Train Epoch: 4 [50000/60000 (83%)]\t1.584674\n",
      "Train Epoch: 4 [52000/60000 (87%)]\t1.518651\n",
      "Train Epoch: 4 [54000/60000 (90%)]\t1.624317\n",
      "Train Epoch: 4 [56000/60000 (93%)]\t1.621942\n",
      "Train Epoch: 4 [58000/60000 (97%)]\t1.556243\n",
      "\n",
      "Test Loss: Average Loss: 0.0151, Accuracy: 9534/10000 95%\n",
      "Train Epoch: 5 [0/60000 (0%)]\t1.523947\n",
      "Train Epoch: 5 [2000/60000 (3%)]\t1.572856\n",
      "Train Epoch: 5 [4000/60000 (7%)]\t1.554454\n",
      "Train Epoch: 5 [6000/60000 (10%)]\t1.553447\n",
      "Train Epoch: 5 [8000/60000 (13%)]\t1.631262\n",
      "Train Epoch: 5 [10000/60000 (17%)]\t1.505960\n",
      "Train Epoch: 5 [12000/60000 (20%)]\t1.550207\n",
      "Train Epoch: 5 [14000/60000 (23%)]\t1.524584\n",
      "Train Epoch: 5 [16000/60000 (27%)]\t1.539240\n",
      "Train Epoch: 5 [18000/60000 (30%)]\t1.653659\n",
      "Train Epoch: 5 [20000/60000 (33%)]\t1.544961\n",
      "Train Epoch: 5 [22000/60000 (37%)]\t1.562302\n",
      "Train Epoch: 5 [24000/60000 (40%)]\t1.543767\n",
      "Train Epoch: 5 [26000/60000 (43%)]\t1.551978\n",
      "Train Epoch: 5 [28000/60000 (47%)]\t1.583592\n",
      "Train Epoch: 5 [30000/60000 (50%)]\t1.565852\n",
      "Train Epoch: 5 [32000/60000 (53%)]\t1.594187\n",
      "Train Epoch: 5 [34000/60000 (57%)]\t1.520712\n",
      "Train Epoch: 5 [36000/60000 (60%)]\t1.569801\n",
      "Train Epoch: 5 [38000/60000 (63%)]\t1.550587\n",
      "Train Epoch: 5 [40000/60000 (67%)]\t1.569458\n",
      "Train Epoch: 5 [42000/60000 (70%)]\t1.552200\n",
      "Train Epoch: 5 [44000/60000 (73%)]\t1.583487\n",
      "Train Epoch: 5 [46000/60000 (77%)]\t1.586838\n",
      "Train Epoch: 5 [48000/60000 (80%)]\t1.524179\n",
      "Train Epoch: 5 [50000/60000 (83%)]\t1.572862\n",
      "Train Epoch: 5 [52000/60000 (87%)]\t1.548431\n",
      "Train Epoch: 5 [54000/60000 (90%)]\t1.557604\n",
      "Train Epoch: 5 [56000/60000 (93%)]\t1.524892\n",
      "Train Epoch: 5 [58000/60000 (97%)]\t1.542240\n",
      "\n",
      "Test Loss: Average Loss: 0.0151, Accuracy: 9563/10000 96%\n",
      "Train Epoch: 6 [0/60000 (0%)]\t1.576152\n",
      "Train Epoch: 6 [2000/60000 (3%)]\t1.522666\n",
      "Train Epoch: 6 [4000/60000 (7%)]\t1.570120\n",
      "Train Epoch: 6 [6000/60000 (10%)]\t1.530922\n",
      "Train Epoch: 6 [8000/60000 (13%)]\t1.578387\n",
      "Train Epoch: 6 [10000/60000 (17%)]\t1.540786\n",
      "Train Epoch: 6 [12000/60000 (20%)]\t1.555260\n",
      "Train Epoch: 6 [14000/60000 (23%)]\t1.538092\n",
      "Train Epoch: 6 [16000/60000 (27%)]\t1.563332\n",
      "Train Epoch: 6 [18000/60000 (30%)]\t1.547754\n",
      "Train Epoch: 6 [20000/60000 (33%)]\t1.549607\n",
      "Train Epoch: 6 [22000/60000 (37%)]\t1.614499\n",
      "Train Epoch: 6 [24000/60000 (40%)]\t1.591879\n",
      "Train Epoch: 6 [26000/60000 (43%)]\t1.575867\n",
      "Train Epoch: 6 [28000/60000 (47%)]\t1.570329\n",
      "Train Epoch: 6 [30000/60000 (50%)]\t1.549684\n",
      "Train Epoch: 6 [32000/60000 (53%)]\t1.544314\n",
      "Train Epoch: 6 [34000/60000 (57%)]\t1.564355\n",
      "Train Epoch: 6 [36000/60000 (60%)]\t1.559889\n",
      "Train Epoch: 6 [38000/60000 (63%)]\t1.550300\n",
      "Train Epoch: 6 [40000/60000 (67%)]\t1.567408\n",
      "Train Epoch: 6 [42000/60000 (70%)]\t1.538000\n",
      "Train Epoch: 6 [44000/60000 (73%)]\t1.530989\n",
      "Train Epoch: 6 [46000/60000 (77%)]\t1.568634\n",
      "Train Epoch: 6 [48000/60000 (80%)]\t1.588069\n",
      "Train Epoch: 6 [50000/60000 (83%)]\t1.561840\n",
      "Train Epoch: 6 [52000/60000 (87%)]\t1.620425\n",
      "Train Epoch: 6 [54000/60000 (90%)]\t1.553291\n",
      "Train Epoch: 6 [56000/60000 (93%)]\t1.550839\n",
      "Train Epoch: 6 [58000/60000 (97%)]\t1.524945\n",
      "\n",
      "Test Loss: Average Loss: 0.0150, Accuracy: 9614/10000 96%\n",
      "Train Epoch: 7 [0/60000 (0%)]\t1.610573\n",
      "Train Epoch: 7 [2000/60000 (3%)]\t1.577722\n",
      "Train Epoch: 7 [4000/60000 (7%)]\t1.508667\n",
      "Train Epoch: 7 [6000/60000 (10%)]\t1.546840\n",
      "Train Epoch: 7 [8000/60000 (13%)]\t1.551457\n",
      "Train Epoch: 7 [10000/60000 (17%)]\t1.524586\n",
      "Train Epoch: 7 [12000/60000 (20%)]\t1.613433\n",
      "Train Epoch: 7 [14000/60000 (23%)]\t1.566707\n",
      "Train Epoch: 7 [16000/60000 (27%)]\t1.549148\n",
      "Train Epoch: 7 [18000/60000 (30%)]\t1.498048\n",
      "Train Epoch: 7 [20000/60000 (33%)]\t1.549069\n",
      "Train Epoch: 7 [22000/60000 (37%)]\t1.540768\n",
      "Train Epoch: 7 [24000/60000 (40%)]\t1.532820\n",
      "Train Epoch: 7 [26000/60000 (43%)]\t1.542186\n",
      "Train Epoch: 7 [28000/60000 (47%)]\t1.576387\n",
      "Train Epoch: 7 [30000/60000 (50%)]\t1.512674\n",
      "Train Epoch: 7 [32000/60000 (53%)]\t1.539175\n",
      "Train Epoch: 7 [34000/60000 (57%)]\t1.578985\n",
      "Train Epoch: 7 [36000/60000 (60%)]\t1.557966\n",
      "Train Epoch: 7 [38000/60000 (63%)]\t1.551635\n",
      "Train Epoch: 7 [40000/60000 (67%)]\t1.568656\n",
      "Train Epoch: 7 [42000/60000 (70%)]\t1.582829\n",
      "Train Epoch: 7 [44000/60000 (73%)]\t1.572805\n",
      "Train Epoch: 7 [46000/60000 (77%)]\t1.567417\n",
      "Train Epoch: 7 [48000/60000 (80%)]\t1.566353\n",
      "Train Epoch: 7 [50000/60000 (83%)]\t1.529528\n",
      "Train Epoch: 7 [52000/60000 (87%)]\t1.545621\n",
      "Train Epoch: 7 [54000/60000 (90%)]\t1.504464\n",
      "Train Epoch: 7 [56000/60000 (93%)]\t1.549215\n",
      "Train Epoch: 7 [58000/60000 (97%)]\t1.530715\n",
      "\n",
      "Test Loss: Average Loss: 0.0150, Accuracy: 9642/10000 96%\n",
      "Train Epoch: 8 [0/60000 (0%)]\t1.516991\n",
      "Train Epoch: 8 [2000/60000 (3%)]\t1.540430\n",
      "Train Epoch: 8 [4000/60000 (7%)]\t1.555275\n",
      "Train Epoch: 8 [6000/60000 (10%)]\t1.542898\n",
      "Train Epoch: 8 [8000/60000 (13%)]\t1.539682\n",
      "Train Epoch: 8 [10000/60000 (17%)]\t1.544445\n",
      "Train Epoch: 8 [12000/60000 (20%)]\t1.629686\n",
      "Train Epoch: 8 [14000/60000 (23%)]\t1.589585\n",
      "Train Epoch: 8 [16000/60000 (27%)]\t1.538640\n",
      "Train Epoch: 8 [18000/60000 (30%)]\t1.556608\n",
      "Train Epoch: 8 [20000/60000 (33%)]\t1.569932\n",
      "Train Epoch: 8 [22000/60000 (37%)]\t1.507676\n",
      "Train Epoch: 8 [24000/60000 (40%)]\t1.531724\n",
      "Train Epoch: 8 [26000/60000 (43%)]\t1.548814\n",
      "Train Epoch: 8 [28000/60000 (47%)]\t1.594889\n",
      "Train Epoch: 8 [30000/60000 (50%)]\t1.525589\n",
      "Train Epoch: 8 [32000/60000 (53%)]\t1.582123\n",
      "Train Epoch: 8 [34000/60000 (57%)]\t1.549776\n",
      "Train Epoch: 8 [36000/60000 (60%)]\t1.564085\n",
      "Train Epoch: 8 [38000/60000 (63%)]\t1.534853\n",
      "Train Epoch: 8 [40000/60000 (67%)]\t1.548237\n",
      "Train Epoch: 8 [42000/60000 (70%)]\t1.504018\n",
      "Train Epoch: 8 [44000/60000 (73%)]\t1.532643\n",
      "Train Epoch: 8 [46000/60000 (77%)]\t1.554046\n",
      "Train Epoch: 8 [48000/60000 (80%)]\t1.526187\n",
      "Train Epoch: 8 [50000/60000 (83%)]\t1.547632\n",
      "Train Epoch: 8 [52000/60000 (87%)]\t1.572473\n",
      "Train Epoch: 8 [54000/60000 (90%)]\t1.542347\n",
      "Train Epoch: 8 [56000/60000 (93%)]\t1.591046\n",
      "Train Epoch: 8 [58000/60000 (97%)]\t1.538134\n",
      "\n",
      "Test Loss: Average Loss: 0.0150, Accuracy: 9641/10000 96%\n",
      "Train Epoch: 9 [0/60000 (0%)]\t1.514845\n",
      "Train Epoch: 9 [2000/60000 (3%)]\t1.563633\n",
      "Train Epoch: 9 [4000/60000 (7%)]\t1.519482\n",
      "Train Epoch: 9 [6000/60000 (10%)]\t1.535121\n",
      "Train Epoch: 9 [8000/60000 (13%)]\t1.552873\n",
      "Train Epoch: 9 [10000/60000 (17%)]\t1.544647\n",
      "Train Epoch: 9 [12000/60000 (20%)]\t1.531180\n",
      "Train Epoch: 9 [14000/60000 (23%)]\t1.555470\n",
      "Train Epoch: 9 [16000/60000 (27%)]\t1.554806\n",
      "Train Epoch: 9 [18000/60000 (30%)]\t1.557351\n",
      "Train Epoch: 9 [20000/60000 (33%)]\t1.528865\n",
      "Train Epoch: 9 [22000/60000 (37%)]\t1.551082\n",
      "Train Epoch: 9 [24000/60000 (40%)]\t1.525514\n",
      "Train Epoch: 9 [26000/60000 (43%)]\t1.568126\n",
      "Train Epoch: 9 [28000/60000 (47%)]\t1.513434\n",
      "Train Epoch: 9 [30000/60000 (50%)]\t1.520054\n",
      "Train Epoch: 9 [32000/60000 (53%)]\t1.551078\n",
      "Train Epoch: 9 [34000/60000 (57%)]\t1.526780\n",
      "Train Epoch: 9 [36000/60000 (60%)]\t1.533277\n",
      "Train Epoch: 9 [38000/60000 (63%)]\t1.546089\n",
      "Train Epoch: 9 [40000/60000 (67%)]\t1.582036\n",
      "Train Epoch: 9 [42000/60000 (70%)]\t1.538946\n",
      "Train Epoch: 9 [44000/60000 (73%)]\t1.533404\n",
      "Train Epoch: 9 [46000/60000 (77%)]\t1.557080\n",
      "Train Epoch: 9 [48000/60000 (80%)]\t1.525144\n",
      "Train Epoch: 9 [50000/60000 (83%)]\t1.528246\n",
      "Train Epoch: 9 [52000/60000 (87%)]\t1.589648\n",
      "Train Epoch: 9 [54000/60000 (90%)]\t1.577743\n",
      "Train Epoch: 9 [56000/60000 (93%)]\t1.541367\n",
      "Train Epoch: 9 [58000/60000 (97%)]\t1.521951\n",
      "\n",
      "Test Loss: Average Loss: 0.0150, Accuracy: 9659/10000 97%\n",
      "Train Epoch: 10 [0/60000 (0%)]\t1.537812\n",
      "Train Epoch: 10 [2000/60000 (3%)]\t1.518620\n",
      "Train Epoch: 10 [4000/60000 (7%)]\t1.538364\n",
      "Train Epoch: 10 [6000/60000 (10%)]\t1.521323\n",
      "Train Epoch: 10 [8000/60000 (13%)]\t1.540963\n",
      "Train Epoch: 10 [10000/60000 (17%)]\t1.498978\n",
      "Train Epoch: 10 [12000/60000 (20%)]\t1.554737\n",
      "Train Epoch: 10 [14000/60000 (23%)]\t1.524284\n",
      "Train Epoch: 10 [16000/60000 (27%)]\t1.542330\n",
      "Train Epoch: 10 [18000/60000 (30%)]\t1.516412\n",
      "Train Epoch: 10 [20000/60000 (33%)]\t1.569978\n",
      "Train Epoch: 10 [22000/60000 (37%)]\t1.521378\n",
      "Train Epoch: 10 [24000/60000 (40%)]\t1.569784\n",
      "Train Epoch: 10 [26000/60000 (43%)]\t1.568964\n",
      "Train Epoch: 10 [28000/60000 (47%)]\t1.504748\n",
      "Train Epoch: 10 [30000/60000 (50%)]\t1.520759\n",
      "Train Epoch: 10 [32000/60000 (53%)]\t1.533115\n",
      "Train Epoch: 10 [34000/60000 (57%)]\t1.541711\n",
      "Train Epoch: 10 [36000/60000 (60%)]\t1.532803\n",
      "Train Epoch: 10 [38000/60000 (63%)]\t1.592212\n",
      "Train Epoch: 10 [40000/60000 (67%)]\t1.517122\n",
      "Train Epoch: 10 [42000/60000 (70%)]\t1.538898\n",
      "Train Epoch: 10 [44000/60000 (73%)]\t1.532306\n",
      "Train Epoch: 10 [46000/60000 (77%)]\t1.516892\n",
      "Train Epoch: 10 [48000/60000 (80%)]\t1.569334\n",
      "Train Epoch: 10 [50000/60000 (83%)]\t1.538583\n",
      "Train Epoch: 10 [52000/60000 (87%)]\t1.553490\n",
      "Train Epoch: 10 [54000/60000 (90%)]\t1.513095\n",
      "Train Epoch: 10 [56000/60000 (93%)]\t1.536266\n",
      "Train Epoch: 10 [58000/60000 (97%)]\t1.549272\n",
      "\n",
      "Test Loss: Average Loss: 0.0149, Accuracy: 9694/10000 97%\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "# from learning_functions import train, test\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "        train(epoch)\n",
    "        test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.540924</td>\n",
       "      <td>1.492586</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.538203</td>\n",
       "      <td>1.491720</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.534481</td>\n",
       "      <td>1.489440</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.527587</td>\n",
       "      <td>1.486569</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.529370</td>\n",
       "      <td>1.486071</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/preston/Projects/fastai_course/MNIST_Digit_identifier/learning_functions.py:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "learn = Learner(dls, neural_net, opt_func=SGD, loss_func=loss_fn)\n",
    "learn.fit(5, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "save_object(neural_net, 'digit_identifier.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
